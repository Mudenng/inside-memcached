# 锁分析

## 锁类型
memcached中用于保护存储对象和内部数据结构的锁有以下几种：

- **item_global_lock**：用于保护整个Hash表结构和全部的数据对象。该锁的粒度非常大，所以一般情况下不会被使用，只有在Hash表扩容时，会将`item_lock(hv)`所使用的锁类型从细粒度的Hash槽锁切换到这个全局锁，因为扩充操作需要调整整个Hash表的结构
- **item_locks**：即Hash槽锁，是较细粒度的用来保护Hash槽和其中对象的锁。并不是每个槽配备了一个锁，而是由几个槽共享一个锁，虽然这样可能会加剧锁竞争，但是可以节约部分内存
- **cache_lock**：这个锁出现的比较频繁，用途也比较多样，现在来看，主要有以下两个用途：（1）保护LRU队列和Hash槽链表（2）保护slab分配器，防止并发修改slab结构，包括分配对象等（3）防止对`get_cas_id()`的并发访问
- **stats_lock**：保护全局统计信息的锁，任何线程需要修改或者访问全局统计信息时必须持有这个锁
- **threads[i].stats.mutex**：保护线程私有统计信息的锁，在X86平台下该锁的意义在于当其他线程可能会并发地访问别的线程的统计信息
- **slabs_lock**：slab分配器内部的锁，用来保护slab分配器的内存操作

##锁的使用
###item_locks
在正常情况下，任何时候对单一item的访问都需要获得相应的item_locks，即Hash槽锁，该锁可以阻止对同一个item的并发访问，同时也保护了在对Hash槽进行遍历查找的过程中，不会出现对Hash槽的并发修改。

需要注意的是，对同一个对象或者处于同一槽中对象的并发读写是很常见的操作，这里使用排他性的锁对item保护难道不会产生非常严重的锁竞争，而影响性能吗？

memcached使用了精妙的设计来优化这个问题，在get对象时，仅仅是在遍历Hash槽的过程中持有该锁，对item数据真正的访问和拷贝操作时并不会持有它，也就是说这个锁真正保护的并不是item本身，而是item所在的Hash槽链表；那么如果在get的同时并发地对一个item进行修改操作，会发生什么呢？显然这个锁对item本身的读写互斥是无能为力的，所以memcached中将item的修改操作分为了两种情况，通过判断目前持有该对象的引用计数，如果当前修改操作的线程是唯一正在访问该对象的线程，那么可以直接修改item的数据，此时是安全的；但是如果还有其他线程也在访问这个item（比如另一个线程在get后正在向网络输出缓存拷贝item的数据，虽然那个线程已经释放了锁，但是对象的引用计数表明有其他线程正在访问对象），所以此时不能安全地直接原地修改item数据，这个时候虽然可以选择继续等待对象被其他线程释放然后再原地修改，但是这种忙等待方式会造成性能的极大损失，而memcached的做法是分配一个新的item对象，将旧item的数据拷贝到新item（此时读旧item是安全的），修改新item后调用replace操作，用新item替换旧item，这个替换的过程并不需要等待其他线程的数据读取操作完成后才进行，因为这个替换操作并没有直接释放旧item，而是当其他线程的读操作完成后减小引用计数，当引用计数达到0时才会真正释放旧item的内存，所以在替换的过程中，旧item和新item互不干扰，已经持有旧item的线程继续进行它的读操作，只不过新item已经取代了Hash表中旧item的位置。

###cache_lock
（1）当修改LRU队列、修改Hash槽链表时，需要持有这个锁，包括`do_item_link()`和`do_item_unlink()`等操作；需要遍历LRU队列时也需要持有锁，包括`item_cache_dump()`、`item_flush_expired()`、`item_stats()`等操作。也就是说这个锁主要保护的就是LRU队列。

（2）保护slab分配器，防止并发修改slab结构，包括分配对象等，这个锁使得slab分配对象不能够并发，在一定程度上成为了性能的最后瓶颈

（3）防止对`get_cas_id()`的并发访问，这个函数的作用是每次调用都返回一个全局唯一的64位id，其内部实现是使用了一个静态变量，每次访问后自增，由于使用了静态变量，所以使用锁进行保护也就不奇怪了。

注意，如果需要同时持有上述的item_locks锁和cache_lock锁，那么它俩之间的加锁顺序是先item_lock，后cache_lock。

###stats_lock和threads[i].stats.mutex
在旧版本的memcached中，所有的统计信息都是全局的，也就是说对任何线程对统计信息的修改都需要持有stats_lock，由于很多操作都涉及到了更新统计信息，所以这种全局加锁在线程并发程度很高的情况下，非常严重地影响了性能，Facebook在只有过程中注意到了这个问题，发现在8核机器上这个锁的CPU占用可以高达20%以上，所以他们做出了修改，将大部分统计信息从全局移到线程私有的，这样它们就不要用全局锁保护了，但是依然需要自己的锁来保护自己不会被其他线程并发访问，不过这时候锁粒度已经小了很多了。新版本的memcached将这个改动也合并了，所以目前除了少数几个统计量依然是全局的，大部分统计量都是线程私有的了。